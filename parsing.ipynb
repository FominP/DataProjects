{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e39a8ba",
   "metadata": {},
   "source": [
    "# Описание задачи\n",
    "Это практическая работа по парсингу различных сервисов с помощью библиотек  requests, BeautifulSoup и Selenium. Нужно получить некоторые данные и сохранить их."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59734371",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "Соберите информацию со всех страниц о происходивших выставках кошек с сайта RU-pets.ru (http://ru-pets.ru/index.php?m=6&c=2&to=1).\n",
    "\n",
    "Данные, которые необходимы:\n",
    "\n",
    "- Дата проведения\n",
    "- Название выставки\n",
    "- Клуб-Организатор\n",
    "\n",
    "Результат необходимо записать в CSV файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e864c8df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего страниц: 77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>«КОТОШЕСТВИЕ»</td>\n",
       "      <td>22-23 октября 2022г.</td>\n",
       "      <td>КЛК Параллель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>«ЛЕТО - 2022»</td>\n",
       "      <td>12-13 июня 2022г.</td>\n",
       "      <td>Самарис</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>«КЭТ-САЛОН-ОКТЯБРЬ»</td>\n",
       "      <td>23 октября 2021г.</td>\n",
       "      <td>КЛК Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>«РОСКОШНАЯ ОСЕНЬ»</td>\n",
       "      <td>9-10 октября 2021г.</td>\n",
       "      <td>КЛК РосКош</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>«ОСЕННИЙ ВЕРНИСАЖ-2021»</td>\n",
       "      <td>2-3 октября 2021г.</td>\n",
       "      <td>УРОФО Грация</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                  date           host\n",
       "0            «КОТОШЕСТВИЕ»  22-23 октября 2022г.  КЛК Параллель\n",
       "1            «ЛЕТО - 2022»     12-13 июня 2022г.        Самарис\n",
       "2      «КЭТ-САЛОН-ОКТЯБРЬ»     23 октября 2021г.     КЛК Москва\n",
       "3        «РОСКОШНАЯ ОСЕНЬ»   9-10 октября 2021г.     КЛК РосКош\n",
       "4  «ОСЕННИЙ ВЕРНИСАЖ-2021»    2-3 октября 2021г.   УРОФО Грация"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "result = []\n",
    "max_page=1\n",
    "\n",
    "try:\n",
    "    response = requests.get('http://ru-pets.ru/index.php?m=6&to=1&c=2')\n",
    "    soup = BeautifulSoup(response.text, 'lxml') \n",
    "    max_page = int(soup\n",
    "                   .find('a', attrs={'title':'Выставки кошек, последняя страница.'})\n",
    "                   .get_text())\n",
    "\n",
    "    if max_page:\n",
    "        print('Всего страниц:', max_page)\n",
    "        \n",
    "    for page in range(1, max_page+1):\n",
    "        response = (requests.get('http://ru-pets.ru/index.php?m=6&to=1&c=2',\n",
    "                                 params={'page': page}))\n",
    "        soup = BeautifulSoup(response.text, 'lxml') \n",
    "        exhibitions = soup.find_all('div', attrs={'class':'listitem'})\n",
    "        \n",
    "        for exhibition in exhibitions:\n",
    "            name = exhibition.find('span', class_='cl-green')\n",
    "            if name:\n",
    "                name = name.get_text().strip()\n",
    "            else:\n",
    "                name = ''\n",
    "\n",
    "            date = exhibition.find('h2')\n",
    "            if date:\n",
    "                date = date.get_text().strip().split(',')[0]\n",
    "            else:\n",
    "                date = ''\n",
    "\n",
    "            host = exhibition.find('div', class_='msgtext').get_text().split('\\n')\n",
    "            if len(host) > 1:\n",
    "                host = (host[1]\n",
    "                        .replace('Клуб - Организатор: ', '')\n",
    "                        .replace(';', '')\n",
    "                        .strip())\n",
    "            else:\n",
    "                host = ''\n",
    "            result.append({'name':name, 'date':date, 'host':host})\n",
    "                   \n",
    "    with open('cat_exhibitions.csv', 'w', encoding='utf-8') as result_file:\n",
    "        field_names = ['name', 'date', 'host']\n",
    "        writer = csv.DictWriter(result_file, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        for row in result:\n",
    "            writer.writerow(row)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    \n",
    "df = pd.read_csv('cat_exhibitions.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89666603",
   "metadata": {},
   "source": [
    "### Selenium\n",
    "Напишите код, который с помощью Selenium соберет характеристики ноутбука (https://www.wildberries.ru/catalog/169234407/detail.aspx)\n",
    "\n",
    "Информация должна быть собрана в формате JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58405269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "URL = 'https://www.wildberries.ru/catalog/169234407/detail.aspx'\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "action = ActionChains(driver)\n",
    "\n",
    "try:\n",
    "    driver.maximize_window()\n",
    "    driver.get(URL)\n",
    "    time.sleep(3)\n",
    "    locator = (By.XPATH, \"//button[contains(@data-link,'Все характеристики и описание')]\")\n",
    "    driver.find_element(*locator).click()\n",
    " \n",
    "    popup = wait.until(\n",
    "        EC.visibility_of_element_located((By.CSS_SELECTOR, \"div.popup.popup-product-details.shown\"))\n",
    "    )\n",
    "\n",
    "    product_data = {}\n",
    "    category_blocks = popup.find_elements(By.CSS_SELECTOR, 'table.product-params__table')\n",
    "    \n",
    "    for block in category_blocks:\n",
    "        caption = block.find_element(By.CSS_SELECTOR, 'caption').text.strip()\n",
    "        product_data[caption] = {}\n",
    "\n",
    "        rows = block.find_elements(By.CSS_SELECTOR, 'tr.product-params__row')\n",
    "        for row in rows:\n",
    "            key = row.find_element(By.CSS_SELECTOR, 'th.product-params__cell').text.strip()\n",
    "            value = row.find_element(By.CSS_SELECTOR, 'td.product-params__cell').text.strip()\n",
    "            product_data[caption][key] = value\n",
    "            \n",
    "    description_section = popup.find_element(By.CSS_SELECTOR, 'section.product-details__description')\n",
    "    description = description_section.find_element(By.CSS_SELECTOR, 'p.option__text').text.strip()\n",
    "    \n",
    "    product_data['Описание'] = description\n",
    "    \n",
    "    with open('specs.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(product_data, f)\n",
    "    \n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    driver.quit()\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd5aed",
   "metadata": {},
   "source": [
    "### Рестораны с ZOON.ru\n",
    "Необходимо собрать данные о ресторанах Томска с сайта ZOON.ru\n",
    "\n",
    "Необходимо собрать следующие данные:\n",
    "\n",
    "- Название заведения\n",
    "- Рейтинг заведения\n",
    "- Направление или направления заведения (пиццерия, бар и.тд)\n",
    " \n",
    "Данные должны быть собраны в CSV-файл, чтобы передать его для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801730e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import undetected_chromedriver as uc\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "URL = 'https://zoon.ru/tomsk/restaurants/'\n",
    "driver = uc.Chrome()\n",
    "wait = WebDriverWait(driver, timeout=10)\n",
    "action = ActionChains(driver)\n",
    "html = ''\n",
    "\n",
    "try:    \n",
    "    driver.get(URL)\n",
    "    driver.implicitly_wait(100)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    while True:\n",
    "        button_next = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"js-next-page\")))\n",
    "        if button_next:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", button_next)\n",
    "            cards = driver.find_elements(By.CLASS_NAME, 'minicard-item__info')\n",
    "            if len(cards)>0:\n",
    "                for card in cards:\n",
    "                    html += card.get_attribute('outerHTML')\n",
    "            driver.execute_script(\"arguments[0].click();\", button_next)\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "        if not button_next:\n",
    "            break\n",
    "            \n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    driver.quit()\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "with open('tomsk-restaurants.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "file = open('tomsk-restaurants.html', 'r', encoding='utf-8')\n",
    "html = file.read()\n",
    "file.close()\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "cards = soup.find_all('div', class_='minicard-item__info')\n",
    "data = []\n",
    "\n",
    "def get_card_data(card):\n",
    "    name = card.find('h2', class_='minicard-item__title').get_text().strip()\n",
    "    rating = card.find('div', class_='z-text--bold').get_text().strip()\n",
    "    cafe_type = (card\n",
    "                 .find('div', class_='minicard-item__features')\n",
    "                 .get_text()\n",
    "                 .strip()\n",
    "                 .replace('\\n', '')\n",
    "                 .replace('•', ', ')[:-2]\n",
    "                )\n",
    "    return {\n",
    "        'name':name,\n",
    "        'rating':rating,\n",
    "        'cafe_type':cafe_type,\n",
    "    }\n",
    "\n",
    "for card in cards:\n",
    "    card_data = get_card_data(card)\n",
    "    data.append(card_data)\n",
    "\n",
    "if len(data) > 0:\n",
    "    with open('tomsk-restaurants.csv', 'w', encoding='utf-8') as f:\n",
    "        fieldnames = data[0].keys()\n",
    "        dict_writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
